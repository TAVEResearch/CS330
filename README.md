# CS 330: Deep Multi-Task and Meta Learning
- Fall 2021

## People

- [Jeiyoon Park](http://jeiyoon.github.io/), [Jieun Han](https://zeunie.notion.site/)

## Materials: https://cs330.stanford.edu/

### Week1
- Course introduction & start of multi-task learning (Chelsea Finn & Karol Hausman), 
- Supervised multi-task learning, transfer learning (Chelsea Finn)

### Week2
- Meta-learning problem statement, black-box meta-learning (Chelsea Finn)
- Optimization-based meta-learning (Chelsea Finn)

### Week3
- Few-shot learning via metric learning (Chelsea Finn)
- Advanced meta-learning topics (Chelsea Finn)
- Variational inference tutorial (TA session)

### Week4
-  Bayesian meta-learning (Chelsea Finn)


## Homeworks ðŸ˜‡
- TBD 

## ~~Optional~~ Must-read things

- [Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics. Kendall et al. (2018)](https://arxiv.org/abs/1705.07115)
- [Universal Language Model Fine-tuning for Text Classification. Howard et al. (2018)](https://arxiv.org/abs/1801.06146)
- [One-shot Learning with Memory-Augmented Neural Networks. Santoro et al. (2016)](https://arxiv.org/abs/1605.06065)
- [Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks. Finn et al. (2017)](https://arxiv.org/abs/1703.03400)
- [Meta-Learning with Differentiable Convex Optimization. Lee et al. (2019)](https://arxiv.org/abs/1904.03758)
- [Matching Networks for One Shot Learning. Vinyals et al. (2017)](https://arxiv.org/abs/1606.04080)
- [Prototypical Networks for Few-shot Learning. Snell et al. (2017)](https://arxiv.org/abs/1703.05175)
- [Meta-Learning without Memorization. Yin et al. (2020)](https://arxiv.org/abs/1912.03820)
- [Conditional Neural Processes. Garnelo et al. (2018)](https://arxiv.org/abs/1807.01613)
- [Meta-Learning Probabilistic Inference For Prediction. Gordon et al. (2019)](https://arxiv.org/abs/1805.09921)


